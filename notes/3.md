## Planning in Markov Decision Processes

* Markov Reward Process - MDP with a fixed policy

* Iterative methods
	* Bellman Equation
	* Backup Operation
	* Sweep

* Contraction Mapping Theorem

* Iterative Policy Evaluation === Policy Iteration

* Policy Iteration vs Value Iteration

* Asynchronous Dynamic Programming
	* In-place - Use only one set of variables
	* Prioritized Sweeping - Use the magnitude of Bellman error to decide which state to update
	* Real-time - Update only states which are relevant to the agent

* Approximate Dynamic Programming
	* Linear Programming